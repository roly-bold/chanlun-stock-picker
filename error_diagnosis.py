#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç¼ è®ºç³»ç»Ÿé”™è¯¯è‡ªåŠ¨è¯Šæ–­ä¸ä¿®å¤å»ºè®®æ¨¡å—
é’ˆå¯¹å¸¸è§é”™è¯¯ç±»å‹ï¼ˆIndexErrorã€KeyErrorã€ModuleNotFoundErrorï¼‰è¿›è¡Œè‡ªåŠ¨åˆ†æ

ç”¨æ³•:
    from error_diagnosis import diagnose_error, suggest_fix
    
    error_msg = "IndexError: index 10 is out of bounds for axis 0 with size 5"
    diagnosis = diagnose_error(error_msg)
    fix = suggest_fix(diagnosis)
"""

import re
from typing import Dict, List, Optional
from dataclasses import dataclass


@dataclass
class ErrorDiagnosis:
    """é”™è¯¯è¯Šæ–­ç»“æœ"""
    error_type: str
    severity: str  # critical, high, medium, low
    description: str
    likely_cause: str
    file_hint: Optional[str] = None
    line_hint: Optional[int] = None


@dataclass
class FixSuggestion:
    """ä¿®å¤å»ºè®®"""
    priority: int  # 1-10, è¶Šé«˜è¶Šä¼˜å…ˆ
    description: str
    code_example: str
    files_to_check: List[str]


class ErrorDiagnoser:
    """é”™è¯¯è¯Šæ–­å™¨"""
    
    # ç¼ è®ºç³»ç»Ÿä¸­å¸¸è§çš„é”™è¯¯æ¨¡å¼
    ERROR_PATTERNS = {
        # IndexError æ¨¡å¼
        r"IndexError.*out of bounds.*axis.*size": {
            "type": "IndexError",
            "severity": "high",
            "description": "æ•°ç»„/åˆ—è¡¨ç´¢å¼•è¶Šç•Œ",
            "likely_cause": "numpy/pandas åˆ‡ç‰‡æ“ä½œæ—¶ç´¢å¼•è¶…å‡ºèŒƒå›´",
            "common_locations": [
                "handle_inclusion() - Kçº¿åŒ…å«å¤„ç†",
                "find_strokes() - æ‰¾ç¬”å‡½æ•°", 
                "calculate_macd() - MACDè®¡ç®—",
                "check_divergence() - èƒŒé©°åˆ¤æ–­"
            ]
        },
        
        r"IndexError.*list index out of range": {
            "type": "IndexError",
            "severity": "high", 
            "description": "åˆ—è¡¨ç´¢å¼•è¶Šç•Œ",
            "likely_cause": "è®¿é—®strokesåˆ—è¡¨æ—¶ç´¢å¼•è¶…å‡ºèŒƒå›´",
            "common_locations": [
                "find_strokes() - ç¬”åˆ—è¡¨è®¿é—®",
                "analyze_stock() - ä¿¡å·åˆ¤æ–­"
            ]
        },
        
        # KeyError æ¨¡å¼
        r"KeyError.*'pinyin'": {
            "type": "KeyError",
            "severity": "medium",
            "description": "DataFrameç¼ºå°‘pinyinåˆ—",
            "likely_cause": "get_all_stocks()æœªæ­£ç¡®æ·»åŠ æ‹¼éŸ³åˆ—",
            "common_locations": [
                "search_stocks() - æœç´¢å‡½æ•°",
                "get_all_stocks() - è‚¡ç¥¨åˆ—è¡¨è·å–"
            ]
        },
        
        r"KeyError.*'(high|low|close|open)'": {
            "type": "KeyError", 
            "severity": "medium",
            "description": "DataFrameç¼ºå°‘ä»·æ ¼åˆ—",
            "likely_cause": "åˆ—åå¤§å°å†™ä¸åŒ¹é…æˆ–æ•°æ®æœªæ­£ç¡®åŠ è½½",
            "common_locations": [
                "handle_inclusion() - Kçº¿å¤„ç†",
                "calculate_zhongshu() - ä¸­æ¢è®¡ç®—"
            ]
        },
        
        # ModuleNotFoundError æ¨¡å¼
        r"ModuleNotFoundError.*chanlun_optimizer": {
            "type": "ModuleNotFoundError",
            "severity": "critical",
            "description": "æ‰¾ä¸åˆ°chanlun_optimizeræ¨¡å—",
            "likely_cause": "æ¨¡å—æ–‡ä»¶æœªæäº¤åˆ°GitHub",
            "common_locations": [
                "app.py - importè¯­å¥"
            ]
        },
        
        r"ModuleNotFoundError.*(pandas|numpy|tushare)": {
            "type": "ModuleNotFoundError",
            "severity": "critical",
            "description": "ç¼ºå°‘æ ¸å¿ƒä¾èµ–åŒ…",
            "likely_cause": "requirements.txtæœªåŒ…å«è¯¥ä¾èµ–",
            "common_locations": [
                "requirements.txt"
            ]
        },
        
        # AttributeError æ¨¡å¼
        r"AttributeError.*'NoneType'.*has no": {
            "type": "AttributeError",
            "severity": "high",
            "description": "ç©ºå¯¹è±¡è°ƒç”¨æ–¹æ³•",
            "likely_cause": "å‡½æ•°è¿”å›Noneä½†ç»§ç»­è°ƒç”¨æ–¹æ³•",
            "common_locations": [
                "get_daily() - æ•°æ®è·å–",
                "analyze_stock() - åˆ†æç»“æœå¤„ç†"
            ]
        },
        
        # ValueError æ¨¡å¼
        r"ValueError.*Length mismatch": {
            "type": "ValueError",
            "severity": "medium",
            "description": "æ•°æ®é•¿åº¦ä¸åŒ¹é…",
            "likely_cause": "DataFrameæ‹¼æ¥æ—¶åˆ—æ•°ä¸ä¸€è‡´",
            "common_locations": [
                "æ•°æ®é¢„å¤„ç†éƒ¨åˆ†"
            ]
        }
    }
    
    @classmethod
    def diagnose(cls, error_message: str, traceback: str = "") -> ErrorDiagnosis:
        """
        è¯Šæ–­é”™è¯¯ç±»å‹
        
        Args:
            error_message: é”™è¯¯ä¿¡æ¯æ–‡æœ¬
            traceback: å®Œæ•´çš„å †æ ˆè·Ÿè¸ªï¼ˆå¯é€‰ï¼‰
            
        Returns:
            ErrorDiagnosis å¯¹è±¡
        """
        error_message = error_message.strip()
        
        # åŒ¹é…é”™è¯¯æ¨¡å¼
        for pattern, info in cls.ERROR_PATTERNS.items():
            if re.search(pattern, error_message, re.IGNORECASE):
                # å°è¯•ä»tracebackä¸­æå–æ–‡ä»¶å’Œè¡Œå·
                file_hint, line_hint = cls._extract_location(traceback)
                
                return ErrorDiagnosis(
                    error_type=info["type"],
                    severity=info["severity"],
                    description=info["description"],
                    likely_cause=info["likely_cause"],
                    file_hint=file_hint,
                    line_hint=line_hint
                )
        
        # æœªçŸ¥é”™è¯¯ç±»å‹
        return ErrorDiagnosis(
            error_type="Unknown",
            severity="medium",
            description="æœªè¯†åˆ«çš„é”™è¯¯ç±»å‹",
            likely_cause="éœ€è¦äººå·¥åˆ†æ",
            file_hint=None,
            line_hint=None
        )
    
    @classmethod
    def _extract_location(cls, traceback: str) -> tuple:
        """ä»tracebackä¸­æå–æ–‡ä»¶è·¯å¾„å’Œè¡Œå·"""
        if not traceback:
            return None, None
            
        # åŒ¹é… File "path", line X
        pattern = r'File "([^"]+)", line (\d+)'
        matches = re.findall(pattern, traceback)
        
        if matches:
            # è¿”å›æœ€åä¸€ä¸ªåŒ¹é…ï¼ˆé€šå¸¸æ˜¯ç”¨æˆ·ä»£ç ï¼‰
            return matches[-1][0], int(matches[-1][1])
        
        return None, None


class FixSuggester:
    """ä¿®å¤å»ºè®®ç”Ÿæˆå™¨"""
    
    FIX_TEMPLATES = {
        "IndexError": {
            "bounds_check": {
                "priority": 10,
                "description": "æ·»åŠ æ•°ç»„è¾¹ç•Œæ£€æŸ¥",
                "code_example": '''
# ä¼˜åŒ–å‰ï¼ˆå®¹æ˜“å‡ºé”™ï¼‰
last_stroke = strokes[-1]

# ä¼˜åŒ–åï¼ˆå®‰å…¨æ£€æŸ¥ï¼‰
if len(strokes) > 0:
    last_stroke = strokes[-1]
else:
    return None  # æˆ–é€‚å½“å¤„ç†

# å¯¹äºç´¢å¼•è®¿é—®
if idx < len(strokes):
    stroke = strokes[idx]
else:
    logger.warning(f"ç´¢å¼•{idx}è¶…å‡ºèŒƒå›´ï¼Œåˆ—è¡¨é•¿åº¦{len(strokes)}")
    return None
                ''',
                "files_to_check": ["app.py"]
            },
            "dataframe_slicing": {
                "priority": 9,
                "description": "DataFrameåˆ‡ç‰‡å‰æ£€æŸ¥é•¿åº¦",
                "code_example": '''
# ä¼˜åŒ–å‰
df_processed = handle_inclusion(df.reset_index(drop=True))
strokes = find_strokes(df_processed)

# ä¼˜åŒ–å
if len(df) < 5:  # æœ€å°æ•°æ®è¦æ±‚
    logger.warning(f"[{symbol}] æ•°æ®ä¸è¶³: {len(df)} å¤©")
    return None

df_processed = handle_inclusion(df.reset_index(drop=True))
if df_processed.empty:
    return None
    
strokes = find_strokes(df_processed)
if len(strokes) < 2:  # è‡³å°‘éœ€è¦2ç¬”
    return None
                ''',
                "files_to_check": ["app.py", "chanlun_optimizer.py"]
            }
        },
        
        "KeyError": {
            "column_check": {
                "priority": 8,
                "description": "æ·»åŠ åˆ—å­˜åœ¨æ€§æ£€æŸ¥",
                "code_example": '''
# ä¼˜åŒ–å‰
pinyin_match = stock_df[stock_df['pinyin'].str.startswith(query)]

# ä¼˜åŒ–å
if 'pinyin' not in stock_df.columns:
    # é‡æ–°è®¡ç®—æ‹¼éŸ³åˆ—
    stock_df['pinyin'] = stock_df['name'].apply(
        lambda x: ''.join(lazy_pinyin(x, style=Style.FIRST_LETTER)).upper()
    )

pinyin_match = stock_df[stock_df['pinyin'].str.startswith(query, na=False)]
                ''',
                "files_to_check": ["app.py", "data_source.py"]
            }
        },
        
        "ModuleNotFoundError": {
            "add_requirements": {
                "priority": 10,
                "description": "æ·»åŠ ç¼ºå¤±çš„ä¾èµ–åˆ°requirements.txt",
                "code_example": '''
# requirements.txt
pydantic>=2.0.0
pydantic-settings>=2.0.0
tenacity>=8.2.0
# å¦‚æœä½¿ç”¨äº†æ–°æ¨¡å—ï¼Œç¡®ä¿æ·»åŠ 
# chanlun_optimizer.py ä¸éœ€è¦å•ç‹¬æ·»åŠ ï¼Œå› ä¸ºå®ƒåœ¨åŒä¸€ç›®å½•
                ''',
                "files_to_check": ["requirements.txt"]
            },
            "git_add": {
                "priority": 10,
                "description": "ç¡®ä¿æ‰€æœ‰.pyæ–‡ä»¶å·²æäº¤",
                "code_example": '''
# æ‰§è¡Œå‘½ä»¤
git add chanlun_optimizer.py
git commit -m "Add missing module"
git push origin master
                ''',
                "files_to_check": [".git"]
            }
        }
    }
    
    @classmethod
    def suggest(cls, diagnosis: ErrorDiagnosis) -> List[FixSuggestion]:
        """
        æ ¹æ®è¯Šæ–­ç»“æœç”Ÿæˆä¿®å¤å»ºè®®
        
        Args:
            diagnosis: é”™è¯¯è¯Šæ–­ç»“æœ
            
        Returns:
            FixSuggestion åˆ—è¡¨ï¼ˆæŒ‰ä¼˜å…ˆçº§æ’åºï¼‰
        """
        suggestions = []
        
        if diagnosis.error_type == "IndexError":
            # IndexError ä¸»è¦ä¿®å¤æ–¹æ¡ˆ
            suggestions.append(cls.FIX_TEMPLATES["IndexError"]["bounds_check"])
            suggestions.append(cls.FIX_TEMPLATES["IndexError"]["dataframe_slicing"])
            
        elif diagnosis.error_type == "KeyError":
            # KeyError ä¸»è¦ä¿®å¤æ–¹æ¡ˆ
            suggestions.append(cls.FIX_TEMPLATES["KeyError"]["column_check"])
            
        elif diagnosis.error_type == "ModuleNotFoundError":
            # ModuleNotFoundError ä¸»è¦ä¿®å¤æ–¹æ¡ˆ
            suggestions.append(cls.FIX_TEMPLATES["ModuleNotFoundError"]["add_requirements"])
            suggestions.append(cls.FIX_TEMPLATES["ModuleNotFoundError"]["git_add"])
        
        # è½¬æ¢ä¸º FixSuggestion å¯¹è±¡
        result = []
        for key, template in suggestions:
            if isinstance(template, dict):
                result.append(FixSuggestion(
                    priority=template["priority"],
                    description=template["description"],
                    code_example=template["code_example"],
                    files_to_check=template["files_to_check"]
                ))
        
        # æŒ‰ä¼˜å…ˆçº§æ’åº
        result.sort(key=lambda x: x.priority, reverse=True)
        return result


def diagnose_error(error_message: str, traceback: str = "") -> str:
    """
    ä¾¿æ·å‡½æ•°ï¼šè¯Šæ–­é”™è¯¯å¹¶è¿”å›å¯è¯»æŠ¥å‘Š
    
    ç”¨æ³•:
        report = diagnose_error(error_msg, traceback)
        print(report)
    """
    diagnosis = ErrorDiagnoser.diagnose(error_message, traceback)
    suggestions = FixSuggester.suggest(diagnosis)
    
    report = []
    report.append("=" * 80)
    report.append("ğŸ” é”™è¯¯è¯Šæ–­æŠ¥å‘Š")
    report.append("=" * 80)
    report.append(f"é”™è¯¯ç±»å‹: {diagnosis.error_type}")
    report.append(f"ä¸¥é‡ç¨‹åº¦: {diagnosis.severity}")
    report.append(f"é—®é¢˜æè¿°: {diagnosis.description}")
    report.append(f"å¯èƒ½åŸå› : {diagnosis.likely_cause}")
    
    if diagnosis.file_hint:
        report.append(f"é—®é¢˜ä½ç½®: {diagnosis.file_hint}:{diagnosis.line_hint}")
    
    report.append("")
    report.append("=" * 80)
    report.append("ğŸ”§ ä¿®å¤å»ºè®®ï¼ˆæŒ‰ä¼˜å…ˆçº§æ’åºï¼‰")
    report.append("=" * 80)
    
    for i, sug in enumerate(suggestions, 1):
        report.append(f"\n{i}. [ä¼˜å…ˆçº§{ sug.priority}] {sug.description}")
        report.append(f"   éœ€è¦æ£€æŸ¥çš„æ–‡ä»¶: {', '.join(sug.files_to_check)}")
        report.append(f"   ä»£ç ç¤ºä¾‹:")
        for line in sug.code_example.strip().split('\n'):
            report.append(f"   {line}")
    
    report.append("")
    report.append("=" * 80)
    
    return "\n".join(report)


# ä¾¿æ·å‡½æ•°
def quick_fix_indexerror(file_path: str, line_num: int, context: str = "") -> str:
    """
    å¿«é€Ÿç”Ÿæˆ IndexError ä¿®å¤ä»£ç 
    """
    return f''"
# åœ¨ {file_path}:{line_num} é™„è¿‘æ·»åŠ è¾¹ç•Œæ£€æŸ¥

# å¦‚æœè®¿é—®åˆ—è¡¨/æ•°ç»„
if index < len(your_list):
    value = your_list[index]
else:
    logger.warning(f"ç´¢å¼•è¶Šç•Œ: {index} >= {len(your_list)}")
    {context if context else "return None  # æˆ–é€‚å½“å¤„ç†"}

# å¦‚æœè®¿é—®DataFrame
if len(df) > required_min_rows:
    result = df.iloc[index]
else:
    logger.warning(f"æ•°æ®ä¸è¶³: {len(df)} rows")
    return None
"""


if __name__ == "__main__":
    # æµ‹è¯•ç”¨ä¾‹
    test_errors = [
        "IndexError: index 10 is out of bounds for axis 0 with size 5",
        "KeyError: 'pinyin'",
        "ModuleNotFoundError: No module named 'chanlun_optimizer'",
    ]
    
    for err in test_errors:
        print(diagnose_error(err))
        print("\n" + "="*80 + "\n")
